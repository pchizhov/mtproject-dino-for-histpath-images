{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f405146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_gray(color: tuple):\n",
    "    (r, g, b) = color\n",
    "    diffs = map(abs, (r-g, r-b, g-b))\n",
    "    return all(diff <= 10 for diff in diffs)\n",
    "\n",
    "\n",
    "def is_useful_tile(tile: Image) -> bool:\n",
    "    tile_copy = tile.copy()\n",
    "    tile_copy.thumbnail((32, 32))\n",
    "    _, most_frequent_color = max(tile_copy.getcolors(maxcolors=1024), key=lambda x: x[0])\n",
    "    return not is_gray(most_frequent_color)\n",
    "\n",
    "\n",
    "def prepare_data(attn_file: str, annot_file: str, drop_white: bool = True):\n",
    "    with open(attn_file) as file:\n",
    "        attention = json.load(file)\n",
    "    with open(annot_file) as file:\n",
    "        annotations = json.load(file)\n",
    "    attention_maps = dict()\n",
    "    for attention_image in attention:\n",
    "        attention_maps[attention_image['image']] = np.array(attention_image['attention_px'], dtype=np.uint8)\n",
    "    categories = [cat['name'] for cat in annotations['categories']]\n",
    "    id2file = {im['id']: im['file_name'] for im in annotations['images']}\n",
    "    images = {im['id']: im for im in annotations['images']}\n",
    "    for annotation in annotations['annotations']:\n",
    "        if 'annotations' not in images[annotation['image_id']]:\n",
    "            images[annotation['image_id']]['annotations'] = []\n",
    "        images[annotation['image_id']]['annotations'].append(annotation)\n",
    "        images[annotation['image_id']]['attention'] = attention_maps[id2file[annotation['image_id']]]\n",
    "    if drop_white:\n",
    "        to_drop = []\n",
    "        for image in images:\n",
    "            if not is_useful_tile(Image.open(f\"new_val/{images[image]['file_name']}\")):\n",
    "                to_drop.append(image)\n",
    "        for image in to_drop:\n",
    "            del images[image]\n",
    "    return images, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_mask_from_annotations(image_size: tuple, annotations: list):\n",
    "    mask = np.full(image_size, False)\n",
    "    i, j = np.ogrid[0: image_size[0], 0: image_size[1]]\n",
    "    for annotation in annotations:\n",
    "        j_, i_, j_size, i_size = annotation['bbox']\n",
    "        scales = (i_size // 2, j_size // 2)\n",
    "        center = (i_ + scales[0], j_ + scales[1])\n",
    "        mask |= (i - center[0]) ** 2 / scales[0] ** 2 + (j - center[1]) ** 2 / scales[1] ** 2 <= 1\n",
    "    return np.array(mask)\n",
    "\n",
    "\n",
    "def binary_masks_from_image(image: dict):\n",
    "    cat_annotations = [[] for _ in range(5)]\n",
    "    for annotation in image['annotations']:\n",
    "        cat_annotations[min(4, annotation['category_id'] - 1)].append(annotation)\n",
    "    binary_masks = [binary_mask_from_annotations(\n",
    "        (image['height'], image['width']),\n",
    "        cat_annotations[i]\n",
    "    ) for i in range(5)]\n",
    "    return binary_masks\n",
    "\n",
    "\n",
    "def metrics_from_attention_map(attention_map: np.array, bin_image: np.array, method: str):\n",
    "    scaled_mask = cv2.resize(attention_map, dsize=bin_image.shape, interpolation=cv2.INTER_CUBIC)\n",
    "    if method == 'Recall':\n",
    "        return np.sum(scaled_mask * bin_image), np.sum(bin_image)\n",
    "    elif method == 'Precision':\n",
    "        return np.sum(scaled_mask * bin_image), np.sum(scaled_mask)\n",
    "    else:\n",
    "        return np.sum(scaled_mask * bin_image), np.sum(np.maximum(scaled_mask, bin_image))\n",
    "\n",
    "\n",
    "def plot_heatmap(images: dict, categories: list, method: str = 'Recall'):\n",
    "    numerator = np.zeros((6, len(categories) + 1))\n",
    "    denominator = np.zeros_like(numerator)\n",
    "    for image in tqdm(images.values(), total=len(images)):\n",
    "        bin_masks = binary_masks_from_image(image)\n",
    "        bin_mask_all_cells = binary_mask_from_annotations((image['height'], image['width']), image['annotations'])\n",
    "        for i, attention_map in enumerate(image['attention']):\n",
    "            for j, bin_mask in enumerate(bin_masks):\n",
    "                num, den = metrics_from_attention_map(attention_map, bin_mask, method)\n",
    "                numerator[i, j] += num\n",
    "                denominator[i, j] += den\n",
    "            num, den = metrics_from_attention_map(attention_map, bin_mask_all_cells, method)\n",
    "            numerator[i, -1] += num\n",
    "            denominator[i, -1] += den\n",
    "    heatmap = numerator / denominator\n",
    "    heatmap = pd.DataFrame(heatmap, columns=[*categories, 'All cells'])\n",
    "    plt.tight_layout()\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    hm = sns.heatmap(heatmap, cbar=False, annot=True, linewidths=0.5, cmap='YlGnBu_r', square=True)\n",
    "    plt.title(f'{method} of attention maps', fontdict={'size': 20}, pad=20)\n",
    "    ax.set_ylabel('Attention maps', fontdict={'size': 16})\n",
    "    ax.set_xlabel('Cell categories', fontdict={'size': 16})\n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e20ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, categories = prepare_data('oneshot_original_th0_5_chkpt10.json', 'new_val/instances_newval.json')\n",
    "categories.remove('Spermatozoa')\n",
    "plot_heatmap(images, categories, 'Recall')\n",
    "plot_heatmap(images, categories, 'Precision')\n",
    "plot_heatmap(images, categories, 'IoU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3794596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "res = []\n",
    "masks = binary_masks_from_image(images[i])\n",
    "for j in range(5):\n",
    "    im = np.array(Image.open('new_val/' + images[i]['file_name']))\n",
    "    im[~masks[j]] //= 2\n",
    "    res.append(im)\n",
    "plt.figure(figsize=(30, 5))\n",
    "ax = plt.axes([0,0,1,1], frameon=False)\n",
    "ax.set_axis_off()\n",
    "plt.imshow(np.hstack(res))\n",
    "plt.imsave('cell_types.png', np.hstack(res), dpi=800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtmetric",
   "language": "python",
   "name": "mtmetric"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
